import React, { useState, useEffect } from 'react';
import { useTranslation } from '../contexts/TranslationContext';
import styles from '../styles/FloatingVoiceAssistant.module.css';

interface FloatingVoiceAssistantProps {
  currentProcessStage?: string;
  onNavigateToLeads?: () => void;
  onNavigateToQuotes?: () => void;
  onNavigateToPayments?: () => void;
  onNavigateToProduction?: () => void;
  onNavigateToInventory?: () => void;
  onNavigateToFulfillment?: () => void;
  onNavigateToCustomers?: () => void;
  onNavigateToAnalytics?: () => void;
  businessData?: {
    hotLeads: number;
    overduePayments: number;
    readyToShip: number;
    totalCustomers: number;
  };
}

function FloatingVoiceAssistant({
  currentProcessStage = 'dashboard',
  onNavigateToLeads,
  onNavigateToQuotes,
  onNavigateToPayments,
  onNavigateToProduction,
  onNavigateToInventory,
  onNavigateToFulfillment,
  onNavigateToCustomers,
  onNavigateToAnalytics,
  businessData
}: FloatingVoiceAssistantProps) {
  const { currentLanguage } = useTranslation();
  
  // Voice command state
  const [isListening, setIsListening] = useState(false);
  const [voiceCommand, setVoiceCommand] = useState('');
  const [voiceResponse, setVoiceResponse] = useState('');
  const [showVoiceResponse, setShowVoiceResponse] = useState(false);
  const [showVoicePanel, setShowVoicePanel] = useState(false);

  // Process-aware voice command suggestions
  const getProcessVoiceCommands = (stage: string) => {
    const commands = {
      'dashboard': [
        'Show business overview',
        'What needs attention today',
        'Go to hot leads',
        'Check payment status'
      ],
      'leads': [
        'Show hot leads',
        'Add new lead',
        'Call next lead',
        'Lead conversion rate'
      ],
      'quotes': [
        'Create quote',
        'Show pending quotes',
        'Quote approval status',
        'Send quote to customer'
      ],
      'payments': [
        'Record payment',
        'Outstanding payments',
        'Customer conversion',
        'Payment reminders'
      ],
      'production': [
        'Production status',
        'Start production',
        'Quality check',
        'Production report'
      ],
      'inventory': [
        'Stock check',
        'Material order',
        'Stock allocation',
        'Inventory report'
      ],
      'fulfillment': [
        'Ready to ship',
        'Dispatch status',
        'Delivery tracking',
        'Confirm delivery'
      ],
      'customers': [
        'Customer profile',
        'VIP customers',
        'Customer feedback',
        'Repeat opportunities'
      ],
      'analytics': [
        'Business performance',
        'Monthly sales',
        'Process efficiency',
        'Show KPIs'
      ]
    };
    return commands[stage as keyof typeof commands] || commands.dashboard;
  };

  // Enhanced voice command processing
  const processVoiceCommand = (command: string) => {
    const lowerCommand = command.toLowerCase();
    let response = '';
    
    // Business intelligence queries
    if (businessData && (lowerCommand.includes('what needs attention') || lowerCommand.includes('àª¶à«àª‚ attention') || lowerCommand.includes('à¤•à¥à¤¯à¤¾ attention'))) {
      response = `Today's priorities: ${businessData.hotLeads} hot leads need calls, ${businessData.overduePayments} overdue payments, ${businessData.readyToShip} orders ready to ship`;
      setVoiceResponse(response);
      setShowVoiceResponse(true);
      return;
    }
    
    // Process-specific navigation commands
    if (lowerCommand.includes('go to') || lowerCommand.includes('show') || lowerCommand.includes('àªœàª¾àª“') || lowerCommand.includes('àª¬àª¤àª¾àªµà«‹')) {
      if (lowerCommand.includes('lead') || lowerCommand.includes('àª²à«€àª¡')) {
        onNavigateToLeads?.();
        response = 'Opening Lead Pipeline management';
      } else if (lowerCommand.includes('quote') || lowerCommand.includes('àª•à«‹àªŸ')) {
        onNavigateToQuotes?.();
        response = 'Opening Quotations management';
      } else if (lowerCommand.includes('payment') || lowerCommand.includes('àªªà«‡àª®à«‡àª¨à«àªŸ')) {
        onNavigateToPayments?.();
        response = 'Opening Payment management';
      } else if (lowerCommand.includes('production') || lowerCommand.includes('àªªà«àª°à«‹àª¡àª•à«àª¶àª¨')) {
        onNavigateToProduction?.();
        response = 'Opening Production management';
      } else if (lowerCommand.includes('inventory') || lowerCommand.includes('àª¸à«àªŸà«‹àª•')) {
        onNavigateToInventory?.();
        response = 'Opening Inventory management';
      } else if (lowerCommand.includes('customer') || lowerCommand.includes('àª—à«àª°àª¾àª¹àª•')) {
        onNavigateToCustomers?.();
        response = 'Opening Customer management';
      } else if (lowerCommand.includes('analytics') || lowerCommand.includes('àª°àª¿àªªà«‹àª°à«àªŸ')) {
        onNavigateToAnalytics?.();
        response = 'Opening Business Analytics';
      }
      
      if (response) {
        setVoiceResponse(response);
        setShowVoiceResponse(true);
        return;
      }
    }
  };

  // Voice recognition setup
  useEffect(() => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = currentLanguage === 'gu' ? 'gu-IN' : currentLanguage === 'hi' ? 'hi-IN' : 'en-IN';

      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        setVoiceCommand(transcript);
        processVoiceCommand(transcript);
        setIsListening(false);
      };

      recognition.onerror = () => {
        setIsListening(false);
      };

      recognition.onend = () => {
        setIsListening(false);
      };

      if (isListening) {
        recognition.start();
      }
    }
  }, [isListening, currentLanguage]);

  const startVoiceRecognition = () => {
    setIsListening(true);
  };

  // Auto-hide voice response after 5 seconds
  useEffect(() => {
    if (showVoiceResponse) {
      const timer = setTimeout(() => {
        setShowVoiceResponse(false);
      }, 5000);
      return () => clearTimeout(timer);
    }
  }, [showVoiceResponse]);

  // Get process stage display name
  const getProcessStageDisplay = (stage: string) => {
    const stageNames = {
      'dashboard': 'ğŸ”„ Dashboard Context',
      'leads': 'ğŸ”¥ Lead Pipeline Context',
      'quotes': 'ğŸ“‹ Quotations Context',
      'payments': 'ğŸ’° Payments Context',
      'production': 'ğŸ­ Production Context',
      'inventory': 'ğŸ“¦ Inventory Context',
      'fulfillment': 'ğŸšš Fulfillment Context',
      'customers': 'ğŸ¤ Customers Context',
      'analytics': 'ğŸ“Š Analytics Context'
    };
    return stageNames[stage as keyof typeof stageNames] || 'ğŸ”„ Dashboard Context';
  };

  return (
    <>
      {/* Voice Response Display */}
      {showVoiceResponse && (
        <div className={styles.voiceResponsePanel}>
          <div className={styles.voiceResponseContent}>
            <span className={styles.voiceResponseIcon}>ğŸ’¬</span>
            <div className={styles.voiceResponseText}>
              <strong>Business Assistant:</strong> {voiceResponse}
            </div>
          </div>
          <button 
            className={styles.closeVoiceResponse} 
            onClick={() => setShowVoiceResponse(false)}
          >
            âœ•
          </button>
        </div>
      )}

      {/* Floating Voice Assistant - WhatsApp Style */}
      <button 
        className={`${styles.floatingVoiceAssistant} ${isListening ? styles.listening : ''}`}
        onClick={startVoiceRecognition}
        onMouseEnter={() => setShowVoicePanel(true)}
        onMouseLeave={() => setShowVoicePanel(false)}
        disabled={isListening}
        aria-label="Voice Assistant"
      >
        {isListening ? 'ğŸ™ï¸' : 'ğŸ¤'}
      </button>

      {/* Voice Command Suggestions Panel */}
      {showVoicePanel && (
        <div className={`${styles.voiceCommandPanel} ${showVoicePanel ? styles.visible : ''}`}>
          <div className={styles.voiceCommandPanelHeader}>
            <span className={styles.voiceCommandTitle}>Voice Commands</span>
            <button 
              className={styles.closeVoicePanel}
              onClick={() => setShowVoicePanel(false)}
            >
              âœ•
            </button>
          </div>
          
          <div className={styles.voiceStageContext}>
            {getProcessStageDisplay(currentProcessStage)}
          </div>
          
          <ul className={styles.voiceCommandSuggestions}>
            {getProcessVoiceCommands(currentProcessStage).map((command, index) => (
              <li 
                key={index}
                className={styles.voiceCommandSuggestion}
                onClick={() => {
                  processVoiceCommand(command);
                  setShowVoicePanel(false);
                }}
              >
                {command}
              </li>
            ))}
          </ul>
          
          <div className={styles.voiceCommandHint}>
            Try: "Go to production" or "Show hot leads"
          </div>
        </div>
      )}
    </>
  );
}

export default FloatingVoiceAssistant;